{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Loading data"],"metadata":{"id":"0D85rnQ1V6jW"}},{"cell_type":"code","execution_count":20,"metadata":{"id":"uc2GYRZzKyzh","outputId":"486df72c-59e6-4f3d-c2ae-888f2bf4e1d6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732337970236,"user_tz":300,"elapsed":5416,"user":{"displayName":"Josh Owen-Guenther","userId":"02116857871520048465"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-11-23 04:59:22--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.23.207, 74.125.203.207, 74.125.204.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.23.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 68606236 (65M) [application/zip]\n","Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n","\n","/tmp/cats_and_dogs_ 100%[===================>]  65.43M  22.6MB/s    in 2.9s    \n","\n","2024-11-23 04:59:26 (22.6 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n","\n"]}],"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n","    -O /tmp/cats_and_dogs_filtered.zip\n","\n","import os\n","import zipfile\n","\n","local_zip = '/tmp/cats_and_dogs_filtered.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp')\n","zip_ref.close()\n","\n","base_dir = '/tmp/cats_and_dogs_filtered'\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'validation')"]},{"cell_type":"markdown","source":["## Reading the Data into arrays"],"metadata":{"id":"xgEKdtTjV8Sx"}},{"cell_type":"code","source":["from PIL import Image\n","import numpy as np\n","\n","cats_dir = os.path.join(train_dir + \"/cats\")\n","dogs_dir = os.path.join(train_dir + \"/dogs\")\n","\n","i = 0\n","NUMBER_OF_EXAMPLES = 5\n","\n","x_train = []\n","y_train = []\n","\n","while i < NUMBER_OF_EXAMPLES:\n","  if i % 2 == 0:\n","    im = Image.open(os.path.join(cats_dir, os.listdir(cats_dir)[i])).convert(\"RGB\")\n","    im_resized = im.resize((150, 150))\n","    x_train.append(np.array(im_resized))\n","    y_train.append(1)\n","  else:\n","    im = Image.open(os.path.join(dogs_dir, os.listdir(dogs_dir)[i])).convert(\"RGB\")\n","    im_resized = im.resize((150, 150))\n","    x_train.append(np.array(im_resized))\n","    y_train.append(0)\n","  i += 1\n","\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)"],"metadata":{"id":"QOhkfFT1K4o1","executionInfo":{"status":"ok","timestamp":1732337972506,"user_tz":300,"elapsed":310,"user":{"displayName":"Josh Owen-Guenther","userId":"02116857871520048465"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Beginning to define the model (this is where you come in, I loaded the pretrained model for you)"],"metadata":{"id":"t7R64c0tV-zh"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","pretrained_model = tf.keras.applications.ResNet50(\n","    include_top=False,\n","    input_shape=(150, 150, 3),\n","    pooling='avg',\n","    classes=2,\n","    weights='imagenet'\n",")"],"metadata":{"id":"7zGbGnknK6uG","executionInfo":{"status":"ok","timestamp":1732337978338,"user_tz":300,"elapsed":1739,"user":{"displayName":"Josh Owen-Guenther","userId":"02116857871520048465"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["# Train the model"],"metadata":{"id":"6iW1sIrpSjTP"}},{"cell_type":"code","source":["from keras import layers, models\n","\n","model = models.Sequential([\n","    pretrained_model,\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(),\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","model.fit(x_train, y_train, epochs=10, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkwYFbRMDPan","executionInfo":{"status":"ok","timestamp":1732338054013,"user_tz":300,"elapsed":70638,"user":{"displayName":"Josh Owen-Guenther","userId":"02116857871520048465"}},"outputId":"8a1f3219-53a8-41e9-e7f0-f71368125ad4"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 44s/step - accuracy: 0.6000 - loss: 0.6838\n","Epoch 2/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.9319e-04\n","Epoch 3/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.9700e-05\n","Epoch 4/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.5263e-05\n","Epoch 5/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 1.7141e-05\n","Epoch 6/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 1.3077e-05\n","Epoch 7/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 1.0261e-05\n","Epoch 8/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.7980e-06\n","Epoch 9/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 5.9128e-06\n","Epoch 10/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 4.6599e-06\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7ab28774f9d0>"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["# Make Predictions"],"metadata":{"id":"T9pMs2hUSqFq"}},{"cell_type":"code","source":["import random\n","import matplotlib.pyplot as plt\n","\n","# Randomly choose between cats and dogs\n","category = random.randrange(1, 3)\n","\n","if category == 1:\n","  category = cats_dir\n","else:\n","  category = dogs_dir\n","\n","# Choose a random image from a list of image files for category, build path\n","image_files = os.listdir(category)\n","random_image_filename = random.choice(image_files)\n","test_image_path = os.path.join(category, random_image_filename)\n","\n","# Open the image, resize it, and normalize it (same preprocessing as training)\n","test_image = Image.open(test_image_path).convert(\"RGB\")\n","test_image_resized = test_image.resize((150, 150))  # Resize to 150x150\n","test_image_array = np.array(test_image_resized) / 255.0  # Normalize the pixel values\n","\n","# Expand the dimensions to match the input shape (batch size of 1)\n","test_image_array = np.expand_dims(test_image_array, axis=0)\n","\n","# Make a prediction using the trained model\n","prediction = model.predict(test_image_array)\n","predicted_class = 'Cat' if prediction[0][0] > 0.5 else 'Dog'\n","\n","# Display result\n","plt.imshow(test_image_resized)\n","plt.axis('off')\n","plt.title(f'Predicted class: {predicted_class}')\n","plt.show()"],"metadata":{"id":"nheIWeK8EWcn"},"execution_count":null,"outputs":[]}]}